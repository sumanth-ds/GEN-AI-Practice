{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d74bef53-bca5-451f-9a5b-765d449fad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75880f47-1d3e-46e3-a3dc-64450a6a9f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8de8ccae-d28e-4fcb-806b-1033ab466c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"gemini-demo.txt\")\n",
    "key = f.read()\n",
    "\n",
    "genai.configure(api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3383665-0c8e-4091-8c10-ed288dcddacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d84e17c-4824-4bbe-a64e-f6cac1fa9549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please ask away! I'm ready for your question.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response =model.generate_content('Hi, this Human i have question for you')\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4023785d-376c-47ef-9ec1-b2b726f4195d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"Please ask away! I'm ready for your question.\\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"avg_logprobs\": -0.3077892523545485\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 10,\n",
       "        \"candidates_token_count\": 13,\n",
       "        \"total_token_count\": 23\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa839bfb-9858-4d56-9fa7-2fc0eb00f318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine you have a HUGE box of LEGO bricks, all different colors and shapes.  You don't know what's in there, just that it's a LOT of LEGOs.\n",
      "\n",
      "Data science is like being a LEGO expert who figures out what's in that box, and then uses that knowledge to build something amazing!\n",
      "\n",
      "Here's how it works:\n",
      "\n",
      "1. **Collecting the LEGOs (Data Collection):**  First, you need to gather all the LEGOs. In data science, this means collecting information.  This information could be anything: the scores of your classmates on a test, the weather each day for a month, or how many people visited a website.\n",
      "\n",
      "2. **Sorting the LEGOs (Data Cleaning & Preparation):**  The box is a mess! Some LEGOs are broken, some are missing pieces, and some are mixed up. You need to clean it up and organize the LEGOs by color, size, and type.  This is like \"cleaning\" and preparing your data – removing mistakes, filling in gaps, and making sure everything is consistent.\n",
      "\n",
      "3. **Building with the LEGOs (Data Analysis & Modeling):** Now, you start to see patterns. Maybe you notice you have a lot of red bricks, or a lot of small square bricks.  You might even realize you have enough bricks to build a specific LEGO model (like a spaceship!). This is where you analyze the data, looking for trends, relationships, and insights.  You might use math and computer programs to help you build \"models\" that predict things.  For example, you might build a model that predicts tomorrow's weather based on today's weather and past weather patterns.\n",
      "\n",
      "4. **Showing off your creation (Data Visualization & Communication):** Finally, you build an amazing LEGO creation! But it's not enough to just build it – you want to show it off! You might take a picture of your spaceship, or even make a video of it flying. In data science, this is about presenting your findings in a clear and understandable way. You might use graphs, charts, or reports to share your discoveries.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "Let's say you want to know if students who study more get better grades.\n",
      "\n",
      "* **Data Collection:** You collect the number of hours each student studied and their test scores.\n",
      "* **Data Cleaning:** You check for any mistakes (e.g., a student accidentally wrote down 100 hours instead of 10).\n",
      "* **Data Analysis:** You look for a relationship between study hours and test scores.  Maybe you find that students who studied more tended to get better grades.\n",
      "* **Data Visualization:** You create a graph showing the relationship between study time and test scores to easily understand the results.\n",
      "\n",
      "So, data science is all about collecting, cleaning, analyzing, and presenting information to find useful insights and solve problems. It's like being a detective for information, using your skills to uncover hidden secrets within the data!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = model.generate_content('What is data science explain clearly with example. explain is easily understand by school student')\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afd38ed9-8a8c-40ac-a172-04deba72c159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can't create images. I am a text-based AI.  To get an image of a man on the moon, I suggest you try one of the following:\n",
      "\n",
      "* **Google Images:** Search for \"astronaut on the moon\" or \"man on the moon\".  You'll find many photos from the Apollo missions.\n",
      "* **Other image search engines:** Bing, DuckDuckGo, etc., also offer image search capabilities.\n",
      "* **Midjourney, Dall-E 2, Stable Diffusion:** These are AI art generators that can create images from text prompts.  You could try a prompt like \"photorealistic astronaut on the moon, high detail, 8k\".  Note that these require accounts and may have usage fees.\n",
      "\n",
      "\n",
      "Remember to specify what kind of image you're looking for (photorealistic, artistic, etc.) for better results in your search or prompt.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = model.generate_content(\"create a image a man on moon\")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6726f960-f38e-45f1-8200-e757ef9607a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GenerativeModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m GenerativeModel(\n\u001b[0;32m      2\u001b[0m     model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-1.5-flash-002\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     system_instruction\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful language translator.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour mission is to translate text in English to French.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     ],\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124mUser input: I like bagels.\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124mAnswer:\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     13\u001b[0m response \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate_content([prompt])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GenerativeModel' is not defined"
     ]
    }
   ],
   "source": [
    "model = GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash-002\",\n",
    "    system_instruction=[\n",
    "        \"You are a helpful language translator.\",\n",
    "        \"Your mission is to translate text in English to French.\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "prompt = \"\"\"\n",
    "User input: I like bagels.\n",
    "Answer:\n",
    "\"\"\"\n",
    "response = model.generate_content([prompt])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7b8f3a-5612-4ae2-a4ab-20febf8e10e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
