{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8627a992-65fd-4030-82c7-5284cd9ffad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "# from langchain_core.embeddings import \n",
    "\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8017f096-9c6c-4f48-9b78-f167fc1955ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install -U langchain_community\n",
    "# %pip install -qU langchain-text-splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0767d1-431c-42ab-8895-2f4934555444",
   "metadata": {},
   "source": [
    "# Loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b9640f8-709c-40a3-ae0b-fb02bed4dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "\n",
    "from langchain_text_splitters import Language, RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cddab1e-afa0-4533-be49-d59df6d27b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:300: UserWarning: Warning: Empty content on page 0 of document Python Data Science Handbook Essential Tools for Working with Data.pdf\n",
      "  warnings.warn(\n",
      "C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:300: UserWarning: Warning: Empty content on page 0 of document MLOps.pdf\n",
      "  warnings.warn(\n",
      "C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:300: UserWarning: Warning: Empty content on page 9 of document MLOps.pdf\n",
      "  warnings.warn(\n",
      "C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:300: UserWarning: Warning: Empty content on page 13 of document MLOps.pdf\n",
      "  warnings.warn(\n",
      "C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:300: UserWarning: Warning: Empty content on page 15 of document MLOps.pdf\n",
      "  warnings.warn(\n",
      "C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:300: UserWarning: Warning: Empty content on page 25 of document MLOps.pdf\n",
      "  warnings.warn(\n",
      "C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:300: UserWarning: Warning: Empty content on page 53 of document MLOps.pdf\n",
      "  warnings.warn(\n",
      "C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:300: UserWarning: Warning: Empty content on page 117 of document MLOps.pdf\n",
      "  warnings.warn(\n",
      "C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:300: UserWarning: Warning: Empty content on page 139 of document MLOps.pdf\n",
      "  warnings.warn(\n",
      "C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:300: UserWarning: Warning: Empty content on page 141 of document MLOps.pdf\n",
      "  warnings.warn(\n",
      "C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:300: UserWarning: Warning: Empty content on page 147 of document MLOps.pdf\n",
      "  warnings.warn(\n",
      "C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:300: UserWarning: Warning: Empty content on page 159 of document MLOps.pdf\n",
      "  warnings.warn(\n",
      "C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:300: UserWarning: Warning: Empty content on page 171 of document MLOps.pdf\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1900"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DirectoryLoader(path = \"./.\", glob='*.pdf',show_progress = True,  use_multithreading = True , loader_cls=PyMuPDFLoader)\n",
    "load = loader.load()\n",
    "len(load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "25b8cd59-23be-48f6-8029-600bc758add2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install unstructured\n",
    "# !pip install pymupdf\n",
    "# !pip install langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b54a6139-834d-466d-8d36-397c95fffe52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'MLOps.pdf', 'file_path': 'MLOps.pdf', 'page': 1, 'total_pages': 185, 'format': 'PDF 1.6', 'title': 'Introducing MLOps', 'author': 'Mark Treveil and the Dataiku Team', 'subject': '', 'keywords': '', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'producer': 'Antenna House PDF Output Library 6.2.609 (Linux64)', 'creationDate': 'D:20201201160716Z', 'modDate': \"D:20211110093528-05'00'\", 'trapped': ''}, page_content='Braund, Mr. Owen Harris\\nMoran, Mr. James\\nHeikkinen, Miss. Laina\\nFutrelle, Mrs. Jacques Heath\\nAllen, Mr. William Henry\\nMcCarthy, Mr. Robert\\nHewlett, Mrs (Mary D Kingcome)\\n22\\n38\\n26\\n35\\n35\\n29\\nmale\\nmale\\nfemale\\nfemale\\nmale\\nmale\\nNatural lang.\\nInteger\\nGender\\nName\\nAge\\nSex\\nRemove rows containing Mr.\\nKeep only rows containing Mr.\\nRemove rows equal to Moran, Mr. James\\nKeep only rows equal to Moran, Mr. James\\nClear cells equal to Moran, Mr. James\\nFilter on Moran, Mr. James\\nFilter on Mr.\\nToggle row highlight\\nShow complete value\\nSplit column on Mr.\\nReplace Mr. by ...\\n450+\\n45,000+\\nCUSTOMERS\\nACTIVE USERS\\nData Preparation\\nDataOps\\nApplications\\nGovernance & MLOps\\nVisualization\\nElastic Architecture Built for the Cloud\\nMachine Learning\\n Everyday AI, \\n Extraordinary People \\n©Dataiku2021 | dataiku.com\\nDataiku is the only platform that provides one simple, consistent UI \\nfor data connection, wrangling, mining, visualization, machine \\nlearning, deployment, and model monitoring, all at enterprise scale.\\nMastering MLOps \\nwith Dataiku\\n1\\n2\\n3\\n4\\nKEY FEATURES FOR A SCALABLE MLOPS STRATEGY INCLUDE:\\nModel input drift detection that looks at the recent data the model has had to score and statistically \\ncompares it with the data on which the model was evaluated.\\nEasier creation of validation feedback loops via Dataiku Evaluation Recipes to compute the true \\nperformance of a saved model against a new validation dataset, plus automated retraining and \\nredeployment.\\nDashboard interfaces dedicated to the monitoring of global pipelines.\\n...and more! See MLOps features with Dataiku in action at dataiku.com\\n')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5b75b86-4880-41ab-91b5-cd32141a4037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7163ee4-3d82-4656-9c94-132ef33d1baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(load[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e39df5-3f7f-4279-b97c-5321f760ddba",
   "metadata": {},
   "source": [
    "# Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50970fa7-70f2-41d9-b203-cb998ca3fd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5010273f-c81c-4c26-8351-cb20c7180888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Braund, Mr. Owen Harris\n",
      "Moran, Mr. James\n",
      "Heikkinen, Miss. Laina\n",
      "Futrelle, Mrs. Jacques Heath\n",
      "Allen, Mr. William Henry\n",
      "McCarthy, Mr. Robert\n",
      "Hewlett, Mrs (Mary D Kingcome)\n",
      "22\n",
      "38\n",
      "26\n",
      "35\n",
      "35\n",
      "29\n",
      "male\n",
      "male\n",
      "female\n",
      "female\n",
      "male\n",
      "male\n",
      "Natural lang.\n",
      "Integer\n",
      "Gender\n",
      "Name\n",
      "Age\n",
      "Sex\n",
      "Remove rows containing Mr.\n",
      "Keep only rows containing Mr.\n",
      "Remove rows equal to Moran, Mr. James\n",
      "Keep only rows equal to Moran, Mr. James\n",
      "Clear cells equal to Moran, Mr. James\n",
      "Filter on Moran, Mr. James\n",
      "Filter on Mr.\n",
      "Toggle row highlight\n",
      "Show complete value\n",
      "Split column on Mr.\n",
      "Replace Mr. by ...\n",
      "450+\n",
      "45,000+\n",
      "CUSTOMERS\n",
      "ACTIVE USERS\n",
      "Data Preparation\n",
      "DataOps\n",
      "Applications\n",
      "Governance & MLOps\n",
      "Visualization\n",
      "Elastic Architecture Built for the Cloud\n",
      "Machine Learning\n",
      " Everyday AI, \n",
      " Extraordinary People \n",
      "©Dataiku2021 | dataiku.com\n",
      "Dataiku is the only platform that provides one simple, consistent UI \n",
      "for data connection, wrangling, mining, visualization, machine \n",
      "learning, deployment, and model monitoring, all at enterprise scale.' metadata={'source': 'MLOps.pdf', 'file_path': 'MLOps.pdf', 'page': 1, 'total_pages': 185, 'format': 'PDF 1.6', 'title': 'Introducing MLOps', 'author': 'Mark Treveil and the Dataiku Team', 'subject': '', 'keywords': '', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'producer': 'Antenna House PDF Output Library 6.2.609 (Linux64)', 'creationDate': 'D:20201201160716Z', 'modDate': \"D:20211110093528-05'00'\", 'trapped': ''}\n",
      "2569\n"
     ]
    }
   ],
   "source": [
    "texts = text_splitter.split_documents(load)\n",
    "print(texts[0])\n",
    "\n",
    "print(len(texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7866c084-d100-4b66-9c25-1558059e1b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "# embeddings_model = HuggingFaceEmbeddings(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a5c4936-fbdc-4695-b1b8-2bc9fe052ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'MLOps.pdf', 'file_path': 'MLOps.pdf', 'page': 0, 'total_pages': 185, 'format': 'PDF 1.6', 'title': 'Introducing MLOps', 'author': 'Mark Treveil and the Dataiku Team', 'subject': '', 'keywords': '', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'producer': 'Antenna House PDF Output Library 6.2.609 (Linux64)', 'creationDate': 'D:20201201160716Z', 'modDate': \"D:20211110093528-05'00'\", 'trapped': ''}, page_content='')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcdd5fd7-f09b-4e80-8028-949a32f19e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, GoogleGenerativeAI, ChatGoogleGenerativeAI\n",
    "\n",
    "f = open(\"gemini-demo.txt\")\n",
    "key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b52c052-6ad0-4dbd-8974-bb3a951bb7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35664912-d59a-47ca-b159-6c711cfbe91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key = key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6b05bb8-326c-4948-bf16-2048fab688e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro\n",
      "models/gemini-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-pro-exp-0801\n",
      "models/gemini-1.5-pro-exp-0827\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-exp-0827\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/learnlm-1.5-pro-experimental\n",
      "models/gemini-exp-1114\n",
      "models/gemini-exp-1121\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/aqa\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1264af03-15e8-4c9a-8601-3c6644a6fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding  = GoogleGenerativeAIEmbeddings(model = 'models/embedding-001', google_api_key=key )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4873c585-66e9-4437-a0d5-116ff50b700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4e116e5d-a28f-4505-af98-2488d29c0e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053947d4-477b-4035-98b6-060a1ea21083",
   "metadata": {},
   "source": [
    "# VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2b7f8ae-ec36-4333-8841-caebb60a00d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d8caeb0-ebef-47fa-85b5-3716adf1a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ba83e59-8a02-4af6-9e62-8d75a029e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vector_store = FAISS.from_documents(\n",
    "    texts, embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b0d28271-ebf1-4118-8878-c6a2787243ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* • If the process is just too heavy-weight for some use-cases, teams will certainly\n",
      "subvert it, and much of the benefit will be lost.\n",
      "Today, process governance is most commonly found in organizations with a tradi‐\n",
      "tionally heavy burden of regulation and compliance, such as finance. Outside of\n",
      "these, it is rare. With ML creeping into all spheres of commercial activity and with\n",
      "rising concern about Responsible AI, we will need new and innovative solutions to\n",
      "this problem that can work for all businesses. \n",
      "Closing Thoughts\n",
      "Given this overview of features required for and processes affected by MLOps, it’s\n",
      "clearly not something data teams—or even the data-driven organization at large—can\n",
      "ignore. Nor is it an item to check off of a list (“yes, we do MLOps!”), but rather a\n",
      "complex interplay between technologies, processes, and people that requires disci‐\n",
      "pline and time to do correctly.\n",
      "The following chapters go deeper into each of the ML model life cycle components at\n",
      "play in MLOps, providing a look at how each should be done to get closer to the ideal\n",
      "MLOps implementation.\n",
      "38 \n",
      "| \n",
      "Chapter 3: Key MLOps Features\n",
      " [{'source': 'MLOps.pdf', 'file_path': 'MLOps.pdf', 'page': 51, 'total_pages': 185, 'format': 'PDF 1.6', 'title': 'Introducing MLOps', 'author': 'Mark Treveil and the Dataiku Team', 'subject': '', 'keywords': '', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'producer': 'Antenna House PDF Output Library 6.2.609 (Linux64)', 'creationDate': 'D:20201201160716Z', 'modDate': \"D:20211110093528-05'00'\", 'trapped': ''}]\n",
      "* Figure 1-3. The realistic picture of a machine learning model life cycle inside an average\n",
      "organization today, which involves many different people with completely different skill\n",
      "sets and who are often using entirely different tools.\n",
      "If the definition (or even the name MLOps) sounds familiar, that’s because it pulls\n",
      "heavily from the concept of DevOps, which streamlines the practice of software\n",
      "changes and updates. Indeed, the two have quite a bit in common. For example, they\n",
      "both center around:\n",
      "• Robust automation and trust between teams\n",
      "• The idea of collaboration and increased communication between teams\n",
      "6 \n",
      "| \n",
      "Chapter 1: Why Now and Challenges\n",
      " [{'source': 'MLOps.pdf', 'file_path': 'MLOps.pdf', 'page': 19, 'total_pages': 185, 'format': 'PDF 1.6', 'title': 'Introducing MLOps', 'author': 'Mark Treveil and the Dataiku Team', 'subject': '', 'keywords': '', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'producer': 'Antenna House PDF Output Library 6.2.609 (Linux64)', 'creationDate': 'D:20201201160716Z', 'modDate': \"D:20211110093528-05'00'\", 'trapped': ''}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"what is mlops\",\n",
    "    k=2,\n",
    "    filter={\"source\": \"MLOps.pdf\"},\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0016f6b-c7ed-492b-996f-50eb28939bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d71269da-0c6c-48d7-a03e-1d5c2a1647fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=0.598884] CHAPTER 3\n",
      "Key MLOps Features\n",
      "Mark Treveil\n",
      "MLOps affects many different roles across the organization and, in turn, many parts\n",
      "of the machine learning life cycle. This chapter introduces the five key components of\n",
      "MLOps (development, deployment, monitoring, iteration, and governance) at a high\n",
      "level as a foundation for Chapters 4 through 8, which delve into the more technical\n",
      "details and requirements of these components.\n",
      "A Primer on Machine Learning\n",
      "To understand the key features of MLOps, it’s essential first to understand how\n",
      "machine learning works and be intimately familiar with its specificities. Though often\n",
      "overlooked in its role as a part of MLOps, ultimately algorithm selection (or how\n",
      "machine learning models are built) can have a direct impact on MLOps processes.\n",
      "At its core, machine learning is the science of computer algorithms that automatically\n",
      "learn and improve from experience rather than being explicitly programmed. The\n",
      "algorithms analyze sample data, known as training data, to build a software model\n",
      "that can make predictions.\n",
      "For example, an image recognition model might be able to identify the type of elec‐\n",
      "tricity meter from a photograph by searching for key patterns in the image that dis‐\n",
      "tinguish each type of meter. Another example is an insurance recommender model,\n",
      "which might suggest additional insurance products that a specific existing customer\n",
      "is most likely to buy based on the previous behavior of similar customers.\n",
      "When faced with unseen data, be it a photo or a customer, the ML model uses what it\n",
      "has learned from previous data to make the best prediction it can based on the\n",
      "assumption that the unseen data is somehow related to the previous data.\n",
      "23\n",
      " [{'source': 'MLOps.pdf', 'file_path': 'MLOps.pdf', 'page': 36, 'total_pages': 185, 'format': 'PDF 1.6', 'title': 'Introducing MLOps', 'author': 'Mark Treveil and the Dataiku Team', 'subject': '', 'keywords': '', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'producer': 'Antenna House PDF Output Library 6.2.609 (Linux64)', 'creationDate': 'D:20201201160716Z', 'modDate': \"D:20211110093528-05'00'\", 'trapped': ''}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    \"what is machine learning?\", k=1, filter={\"source\": 'MLOps.pdf'}\n",
    ")\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aeb82bde-2c3b-4eaa-91e1-c5ed23880853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'• If the process is just too heavy-weight for some use-cases, teams will certainly\\nsubvert it, and much of the benefit will be lost.\\nToday, process governance is most commonly found in organizations with a tradi‐\\ntionally heavy burden of regulation and compliance, such as finance. Outside of\\nthese, it is rare. With ML creeping into all spheres of commercial activity and with\\nrising concern about Responsible AI, we will need new and innovative solutions to\\nthis problem that can work for all businesses. \\nClosing Thoughts\\nGiven this overview of features required for and processes affected by MLOps, it’s\\nclearly not something data teams—or even the data-driven organization at large—can\\nignore. Nor is it an item to check off of a list (“yes, we do MLOps!”), but rather a\\ncomplex interplay between technologies, processes, and people that requires disci‐\\npline and time to do correctly.\\nThe following chapters go deeper into each of the ML model life cycle components at\\nplay in MLOps, providing a look at how each should be done to get closer to the ideal\\nMLOps implementation.\\n38 \\n| \\nChapter 3: Key MLOps Features\\n Figure 1-3. The realistic picture of a machine learning model life cycle inside an average\\norganization today, which involves many different people with completely different skill\\nsets and who are often using entirely different tools.\\nIf the definition (or even the name MLOps) sounds familiar, that’s because it pulls\\nheavily from the concept of DevOps, which streamlines the practice of software\\nchanges and updates. Indeed, the two have quite a bit in common. For example, they\\nboth center around:\\n• Robust automation and trust between teams\\n• The idea of collaboration and increased communication between teams\\n6 \\n| \\nChapter 1: Why Now and Challenges\\n Figure 1-1. Representation of the exponential growth of MLOps (not the parallel growth\\nof the term “ModelOps”)\\nDefining MLOps and Its Challenges\\nAt its core, MLOps is the standardization and streamlining of machine learning life\\ncycle management (Figure 1-2). But taking a step back, why does the machine learn‐\\ning life cycle need to be streamlined? On the surface, just looking at the steps to go\\nfrom business problem to a machine learning model at a very high level, it seems\\nstraightforward.\\nFor most traditional organizations, the development of multiple machine learning\\nmodels and their deployment in a production environment are relatively new. Until\\nrecently, the number of models may have been manageable at a small scale, or there\\nwas simply less interest in understanding these models and their dependencies at a\\ncompany-wide level. With decision automation (that is, an increasing prevalence of\\ndecision making that happens without human intervention), models become more\\ncritical, and, in parallel, managing model risks becomes more important at the top\\nlevel.\\nThe reality of the machine learning life cycle in an enterprise setting is much more\\ncomplex, in terms of needs and tooling (Figure 1-3).\\n4 \\n| \\nChapter 1: Why Now and Challenges\\n CHAPTER 3\\nKey MLOps Features\\nMark Treveil\\nMLOps affects many different roles across the organization and, in turn, many parts\\nof the machine learning life cycle. This chapter introduces the five key components of\\nMLOps (development, deployment, monitoring, iteration, and governance) at a high\\nlevel as a foundation for Chapters 4 through 8, which delve into the more technical\\ndetails and requirements of these components.\\nA Primer on Machine Learning\\nTo understand the key features of MLOps, it’s essential first to understand how\\nmachine learning works and be intimately familiar with its specificities. Though often\\noverlooked in its role as a part of MLOps, ultimately algorithm selection (or how\\nmachine learning models are built) can have a direct impact on MLOps processes.\\nAt its core, machine learning is the science of computer algorithms that automatically\\nlearn and improve from experience rather than being explicitly programmed. The\\nalgorithms analyze sample data, known as training data, to build a software model\\nthat can make predictions.\\nFor example, an image recognition model might be able to identify the type of elec‐\\ntricity meter from a photograph by searching for key patterns in the image that dis‐\\ntinguish each type of meter. Another example is an insurance recommender model,\\nwhich might suggest additional insurance products that a specific existing customer\\nis most likely to buy based on the previous behavior of similar customers.\\nWhen faced with unseen data, be it a photo or a customer, the ML model uses what it\\nhas learned from previous data to make the best prediction it can based on the\\nassumption that the unseen data is somehow related to the previous data.\\n23\\n'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever()\n",
    "context = retriever.invoke(\"what is mlops\")\n",
    "\n",
    "main_context = \" \".join([doc.page_content for doc in context])\n",
    "\n",
    "main_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bfecb9e9-3797-46cb-8e7f-094bbacb1bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langchain_chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5d8e551c-f9d4-4866-942e-4f0024ef7f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Your are helpfull ai assistant. Your name is qa Bot.  Answer the question based on the context : {context}. Answer the question {question}. summarize the given context in point wise If any thing asked other than context reply in polite.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d83a3ae1-6015-45be-a23a-9841710e61d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(\n",
    "    prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8fe19664-6665-4de4-bea3-57185f4f3a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model = 'gemini-1.5-flash-002' ,api_key= key )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e7361dfd-4e92-484f-ab9b-ded82635a7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "34400191-7b3f-44d0-a7a3-8f7e05a39fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using for custom rag chain\n",
    "def retriever(query):\n",
    "    retrieval = vector_store.as_retriever()\n",
    "    context = retrieval.invoke(query) \n",
    "    metadata =  ([ v for i in context for j, v in i.metadata ])\n",
    "    print(metadata)\n",
    "    return '\\n\\n'.join([i.page_content for i in context])\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "63b4c57b-f169-4188-92e6-47baa5a49b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using for custom rag chain\n",
    "def retriever(query):\n",
    "    retrieval = vector_store.as_retriever()\n",
    "    context = retrieval.invoke(query) \n",
    "    return '\\n\\n'.join([i.page_content for i in context])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "7f35ef8b-0b1b-4ac3-9499-8d81a68859ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[\\n5\\n]:\\n names\\n.\\nstr\\n.\\ncapitalize\\n()\\nOut[5]: 0    Peter\\n        1     Paul\\n        2     None\\n        3     Mary\\n        4    Guido\\n        dtype: object\\nUsing tab completion on this str attribute will list all the vectorized string methods available to\\nPandas.\\nTables of Pandas String Methods\\nIf you have a good understanding of string manipulation in Python, most of Pandas’ string syntax is\\nintuitive enough that it’s probably sufficient to just list a table of available methods; we will start\\nwith that here, before diving deeper into a few of the subtleties. The examples in this section use the\\nfollowing series of names:\\nIn\\n[\\n6\\n]:\\n monte\\n =\\n pd\\n.\\nSeries\\n([\\n'Graham Chapman'\\n,\\n 'John Cleese'\\n\\n\\ncategories\\n)\\nHere is a representative entry from the data:\\nIn\\n[\\n9\\n]:\\n print\\n(\\ntrain\\n.\\ndata\\n[\\n5\\n])\\nFrom: dmcgee@uluhe.soest.hawaii.edu (Don McGee)\\nSubject: Federal Hearing\\nOriginator: dmcgee@uluhe\\nOrganization: School of Ocean and Earth Science and Technology\\nDistribution: usa\\nLines: 10\\nFact or rumor....?  Madalyn Murray O'Hare an atheist who eliminated the\\nuse of the bible reading and prayer in public schools 15 years ago is now\\ngoing to appear before the FCC with a petition to stop the reading of the\\nGospel on the airways of America.  And she is also campaigning to remove\\nChristmas programs, songs, etc from the public schools.  If it is true\\nthen mail to Federal Communications Commission 1919 H Street Washington DC\\n20054 expressing your opposition to her request.  Reference Petition number\\n2493.\\nIn order to use this data for machine learning, we need to be able to convert the content of each string\\ninto a vector of numbers. For this we will use the TF–IDF vectorizer (discussed in “Feature\\nEngineering” ), and create a pipeline that attaches it to a multinomial naive Bayes classifier:\\nIn\\n[\\n10\\n]:\\n from\\n\\n\\nMakoto Miyazaki is a data scientist at Dataiku and responsible for delivering hands-\\non consulting services using Dataiku DSS for European and Japanese clients. Makoto\\nholds a bachelor’s degree in economics and a master’s degree in data science, and he\\nwas also a former financial journalist with a wide range of beats, including nuclear\\nenergy and economic recoveries from the tsunami.\\nLynn Heidmann received her bachelor’s degree in journalism/mass communications\\nand anthropology from the University of Wisconsin-Madison in 2008 and decided to\\nbring her passion for research and writing into the world of tech. She spent seven\\nyears in the San Francisco Bay Area writing and running operations with Google and\\nsubsequently Niantic before moving to Paris to head content initiatives at Dataiku. In\\nher current role, Lynn follows and writes about technological trends and develop‐\\nments in the world of data and AI.\\nColophon\\nThe animal on the cover of Introducing MLOps is an African moth called Bunaeopsis\\noubie, also known as Zaddach’s Emperor, that can be found across central and eastern\\nAfrica, from Angola to Eritrea. It is a member of the Saturniidae family, which\\nincludes one thousand species of the world’s largest moths.\\nThis African moth has one of the largest wingspans, stretching up to 10 inches, mak‐\\ning it bigger than some birds. Its wings have distinctive markings: one reddish brown\\ncircle on each of the four wings, dark brown stripes underneath, and white strokes\\nbordering the thorax and along the outer edges of each wing. Moth antennae are\\nthick and feathered. Their entire bodies repel water with a wax coating that covers\\ntheir hairs and the scales on their wings.\\nMoths tend to be attracted to white, fragrant flowers, which they sniff out easily at\\nnight and pollinate well with their fuzzy, sticky bodies. Many animals and birds\\ndepend on moths in their diets, including owls and bats. Moth caterpillars are prey to\\nlizards, birds, and many small mammals.\\nMany of the animals on O’Reilly’s covers are endangered; all of them are important to\\nthe world.\\nThe cover illustration is by Karen Montgomery, based on a black and white engraving\\nfrom Encyclopedie D’Histoire Naturelle. The cover fonts are Gilroy Semibold and\\nGuardian Sans. The text font is Adobe Minion Pro; the heading font is Adobe Myriad\\nCondensed; and the code font is Dalton Maag’s Ubuntu Mono.\\n\\n\\nHow to Contact Us\\nPlease address comments and questions concerning this book to the publisher:\\nO’Reilly Media, Inc.\\n1005 Gravenstein Highway North\\nSebastopol, CA 95472\\n800-998-9938 (in the United States or Canada)\\n707-829-0515 (international or local)\\n707-829-0104 (fax)\\nWe have a web page for this book, where we list errata, examples, and any additional\\ninformation. You can access this page at https://oreil.ly/intro-mlops.\\nEmail bookquestions@oreilly.com to comment or ask technical questions about this\\nbook.\\nFor news and information about our books and courses, visit http://oreilly.com.\\nFind us on Facebook: http://facebook.com/oreilly\\nFollow us on Twitter: http://twitter.com/oreillymedia\\nWatch us on YouTube: http://www.youtube.com/oreillymedia\\nAcknowledgments\\nWe would like to thank the entire Dataiku team for their support in developing this\\nbook, from conception to completion. It’s been a true team effort and, like most\\nthings we do at Dataiku, rooted in fundamental collaboration between countless peo‐\\nple and teams.\\nThanks to those who supported our vision from the beginning of writing this book\\nwith O’Reilly. Thanks to those who stepped in to help with writing and editing.\\nThanks to those who provided honest feedback (even when it meant more writing\\nand rewriting and re-rewriting). Thanks to those who were internal cheerleaders and,\\nof course, those who helped us promote the finished product to the world.\\nPreface \\n| \\nxi\\n\""
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever(\"what is my name\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "7e85eb60-403d-41b2-b712-e9cf9f70c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_chain = {\"context\" : retriever, \"question\": RunnablePassthrough()} | prompt_template | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "94ae593e-3a54-451a-b8da-61311e996d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided text, MLOps is the standardization and streamlining of machine learning life cycle management.  It's heavily influenced by DevOps principles, focusing on automation, collaboration, and communication between teams to manage the entire lifecycle of machine learning models, from development and deployment to monitoring, iteration, and governance.\n",
      "\n",
      "Here's a summary of the provided text in point form:\n",
      "\n",
      "* **MLOps Definition:** MLOps streamlines the machine learning model lifecycle, mirroring DevOps practices for software.  Key aspects include automation, collaboration, and communication.\n",
      "\n",
      "* **The Need for MLOps:**  The increasing use of machine learning in decision-making processes necessitates better management of model development, deployment, and risk.  Traditional methods are insufficient for the complexity of modern machine learning projects.\n",
      "\n",
      "* **MLOps Challenges:**  The machine learning lifecycle in enterprises is complex, involving diverse teams, skill sets, and tools.  Overly heavyweight processes can lead to subversion and loss of benefits.\n",
      "\n",
      "* **Key MLOps Components:**  The text highlights five key components: development, deployment, monitoring, iteration, and governance.  These are explored in more detail in subsequent chapters (not included in this excerpt).\n",
      "\n",
      "* **Relationship to DevOps:** MLOps shares core principles with DevOps, including robust automation and trust between teams, as well as fostering collaboration and communication.\n",
      "\n",
      "* **MLOps and Responsible AI:** Growing concerns about Responsible AI necessitate innovative MLOps solutions applicable to all businesses, not just heavily regulated industries.\n",
      "\n",
      "* **Algorithm Selection's Role:**  The choice of machine learning algorithms directly impacts MLOps processes, highlighting the importance of considering this aspect within the broader MLOps framework.\n",
      "\n",
      "\n",
      "I hope this helps! Let me know if you have any other questions within the scope of this document.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(custom_chain.invoke(\"what is mlops\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d905135d-bfb8-40db-b49e-b8de9faacdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided text, you uploaded the file \"Python Data Science Handbook Essential Tools for Working with Data.pdf\" multiple times.  The exact number of times is not explicitly stated, but it appears at least three times within the given code examples.\n",
      "\n",
      "Here's a point-wise summary of the context:\n",
      "\n",
      "* **Magic Commands in Jupyter:** The text demonstrates the use of the `%history` magic command to access previous inputs.\n",
      "* **Saving Figures:**  It shows how to save figures generated in Python using `savefig()`,  and how to determine supported file types using `fig.canvas.get_supported_filetypes()`.  Supported formats include PNG, JPG, PDF, SVG, etc.\n",
      "* **Array Manipulation with NumPy:** An example uses NumPy to perform calculations and write results to specific elements of an array.\n",
      "* **File System Operations:** The examples include using shell commands (`ls`, `cp`) within a Jupyter notebook to list and copy files.\n",
      "* **Multiple uploads of PDF:** The PDF \"Python Data Science Handbook Essential Tools for Working with Data.pdf\" is mentioned multiple times within the code examples, suggesting multiple uploads or references to the same file.\n",
      "\n",
      "I apologize, but I cannot answer questions outside the provided context.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(custom_chain.invoke(\"how may pdf i uploaded\").content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "792e20d4-e443-430a-a204-5e69a1e1160a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided text, you have uploaded one document:  `Python Data Science Handbook Essential Tools for Working with Data.pdf`.  This document is mentioned multiple times.\n",
      "\n",
      "\n",
      "Here's a point-wise summary of the provided context:\n",
      "\n",
      "* **File system operations:** The context shows examples of using the `ls` command to list files and directories, and the `cp` command to copy files.\n",
      "* **IPython magic commands:**  The text demonstrates the use of IPython magic commands `%history` (to access previous inputs) and `%memit` (implicitly referenced, as its functionality is described).  `%mprun` (for memory profiling) is also mentioned.\n",
      "* **Memory profiling:** An example using `%mprun` shows how to analyze memory usage of a Python function line by line.  It highlights the memory impact of creating and deleting large lists.\n",
      "* **Array manipulation with NumPy:**  The example shows using NumPy to create an array and write results to specific elements.\n",
      "* **IPython resources:** The text lists several online resources for learning more about IPython, including the IPython website, nbviewer, a gallery of notebooks, and video tutorials.\n",
      "\n",
      "\n",
      "I apologize, but I cannot answer questions outside the provided text.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(custom_chain.invoke(\"how may documents i uploaded\").content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "b78aa0f0-e168-4844-a743-45e33016e0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am QA Bot, and I will do my best to answer your questions.  However, the provided text is a snippet from a book chapter on MLOps, focusing specifically on deployment to production. It does *not* contain end-to-end MLOps code.  The code shown is a snippet related to plotting data (likely from matplotlib), not the overall MLOps pipeline.\n",
      "\n",
      "Here's a point-wise summary of the provided context:\n",
      "\n",
      "* **Production Deployment is Crucial in MLOps:** The text highlights the importance of deploying machine learning models to production.\n",
      "* **Efficient Processes and Tools are Essential:**  Successful deployment relies on having the right processes and tools in place to ensure speed and efficiency.\n",
      "* **Leveraging Existing CI/CD Best Practices:**  Many successful elements, especially Continuous Integration/Continuous Delivery (CI/CD) best practices, are already established and can be adapted for machine learning models.\n",
      "* **Scalable Foundation:** Applying these practices builds a solid foundation for scaling MLOps as the business grows.\n",
      "\n",
      "\n",
      "To get end-to-end MLOps code, you would need to specify the tools and technologies you want to use (e.g., TensorFlow, scikit-learn, Kubernetes, AWS SageMaker, Azure ML, etc.).  An end-to-end MLOps pipeline typically involves many stages beyond deployment, including data ingestion, model training, evaluation, and monitoring.  Providing such code would be a very extensive undertaking.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(custom_chain.invoke(\"give code for end to end for mlops\").content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "232eec95-5482-48a9-a18e-eb271139e577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I cannot provide a point-wise summary of the second document because the provided text is a fragmented excerpt from what seems to be a technical book or manual about data science and machine learning, specifically mentioning topics like model validation, version control, and specific algorithms (XGBoost).  The snippets don't form a coherent whole.  To summarize effectively, I would need the complete text of the second document (MLOps.pdf).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(custom_chain.invoke(\"give me summary of 2nd document\").content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "b3a200ce-ebb4-4b7b-92d0-4c2cd13abe5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main theme of the MLOps book is addressing the challenges of scaling machine learning from experimentation to production environments within organizations.  This involves managing the complexities of both machine learning models and the organizational structure.\n",
      "\n",
      "Here's a point-wise summary of the provided context:\n",
      "\n",
      "* **The Shift to Real-World ML:** Machine learning has moved from academia to widespread business application, creating new challenges.\n",
      "* **MLOps's Role in Scaling:** MLOps is crucial for managing the increasing number of models in production (from tens to thousands).\n",
      "* **Target Audience:** The book is aimed at analytics and IT operations managers responsible for scaling ML in production.\n",
      "* **Book Structure:** The book is divided into three parts: introduction to MLOps,  the ML model lifecycle (development, production, monitoring, governance), and real-world examples of MLOps implementations.\n",
      "* **Key Challenges:** The book highlights the complexities of managing multiple models, including technical and business aspects, and the importance of Responsible AI.\n",
      "* **Responsible AI:**  The book emphasizes the need for explainability, accountability, and traceability in machine learning models, especially concerning decision automation.  It stresses the interplay between MLOps and Responsible AI.\n",
      "* **MLOps for Scale:**  MLOps is presented as essential not only for risk mitigation but also for achieving the economies of scale associated with deploying many successful models.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(custom_chain.invoke(\"main theme of mlops book\").content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "a5c22ea6-49a7-4f2f-bb43-2ae4d394d586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main theme of `MLOps.pdf` is the application of MLOps principles to streamline and standardize the machine learning lifecycle management within organizations.  Here's a summary in points:\n",
      "\n",
      "* **Introduction to MLOps:** The document defines MLOps as the standardization and streamlining of the machine learning lifecycle, highlighting the increasing importance of managing model risks in a world of automated decision-making.  It contrasts the simplified theoretical view of the ML lifecycle with the complex reality within enterprises.\n",
      "\n",
      "* **MLOps and DevOps Parallels:**  The document draws parallels between MLOps and DevOps, emphasizing the shared focus on automation, trust, collaboration, and communication between teams.\n",
      "\n",
      "* **Key MLOps Features:**  Chapter 3 introduces five key components of MLOps: development, deployment, monitoring, iteration, and governance.  It briefly explains the importance of algorithm selection in the MLOps process.\n",
      "\n",
      "* **Real-World Examples:** The document promises to provide real-world examples (using fictional company names) illustrating MLOps implementation and implications at scale in later chapters.\n",
      "\n",
      "* **Typographical Conventions:**  The document details the typographical conventions used throughout the book.\n",
      "\n",
      "\n",
      "The provided text is an introduction and doesn't fully elaborate on the technical details or real-world examples promised in later chapters.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(custom_chain.invoke(\"main theme of mlops.pdf\").content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "e84f2822-3f26-458f-af38-92d1afc1d54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main theme of *Python Data Science Handbook: Essential Tools for Working with Data* is to provide a practical guide to using Python for data science.  Here's a point-wise summary of the provided text:\n",
      "\n",
      "* **Focus on core Python data science packages:** The book concentrates on five essential Python packages: IPython/Jupyter, NumPy, Pandas, Matplotlib, and Scikit-learn.  Each is covered in a dedicated chapter.\n",
      "\n",
      "* **Python 3 Syntax with Python 2 Compatibility:** The book primarily uses Python 3 syntax but notes any incompatibilities with Python 2.\n",
      "\n",
      "* **Data Science Defined:** The preface attempts to define data science, acknowledging its ambiguity but emphasizing its cross-disciplinary nature, referencing Drew Conway's Data Science Venn Diagram.\n",
      "\n",
      "* **Practical Approach:** The book aims to be practical and job-oriented, providing usable code examples.\n",
      "\n",
      "* **Supplemental Materials:**  Code examples and other supplementary materials are available online via GitHub.\n",
      "\n",
      "* **Copyright and Usage:** Standard copyright and usage information for the book is included.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(custom_chain.invoke(\"main theme of Python Data Science Handbook Essential Tools for Working with Data.pdf\").content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "673c1fb7-e86b-4c26-9ccd-c7408b5724d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but the provided text does not contain any information about Modi.  The text focuses on data science concepts, libraries (NumPy, Pandas, Scikit-learn, Matplotlib), machine learning model deployment, and mentions several individuals (Ariel Sharon, Colin Powell, etc.) in the context of image processing.\n",
      "\n",
      "\n",
      "Here's a summary of the provided text in point form:\n",
      "\n",
      "* **Data Science Concepts:**  The text covers various data science concepts including data representation, data types, NumPy arrays, Pandas DataFrames, and data manipulation techniques.\n",
      "* **Machine Learning:** It touches upon machine learning concepts like supervised and unsupervised learning, using examples like Iris classification and clustering.  Eigenfaces are mentioned as an example.\n",
      "* **Visualization:**  The text refers to visualizing data using Matplotlib, including errorbars.\n",
      "* **Model Deployment:** A significant portion discusses deploying machine learning models to production, including CI/CD pipelines.\n",
      "* **Libraries:**  The text mentions and utilizes several Python libraries: NumPy, Pandas, Scikit-learn, and Matplotlib.\n",
      "* **Image Processing:**  The text briefly mentions image processing and shows a list of names (presumably associated with images).\n",
      "\n",
      "I apologize that I cannot answer your question about Modi as it is outside the scope of this document.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(custom_chain.invoke(\"who is modi\").content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "5890439d-2aa6-4b71-bedb-dd966f178774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided text describes several image datasets used in machine learning examples, not images from a specific book.  Here's a point-wise summary of the datasets mentioned:\n",
      "\n",
      "\n",
      "* **LFW People Dataset:** Contains 2,370 images, each with 2,914 pixels.  These are facial images.\n",
      "\n",
      "* **Digits Dataset:**  Includes 1,797 images, each an 8x8 grid of pixels (64 pixels total).  These are likely handwritten digits.\n",
      "\n",
      "* **MNIST Dataset:** This dataset comprises 70,000 images, each 28x28 pixels (784 pixels total).  These are also likely handwritten digits.\n",
      "\n",
      "\n",
      "The text also mentions a list of image file names (`imgs_to_use`), but doesn't provide the actual image data itself.  It only shows that this list includes names like 'camera', 'text', 'coins', etc., suggesting a variety of image types.  There's no information on the dimensions or other properties of these images.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(custom_chain.invoke(\"give me the images in the book\").content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "548961a0-75d0-461a-bdab-2336908d595c",
   "metadata": {},
   "outputs": [
    {
     "ename": "GoogleGenerativeAIError",
     "evalue": "Error embedding content: Timeout of 60.0s exceeded, last exception: 503 failed to connect to all addresses; last error: UNKNOWN: ipv4:216.58.196.170:443: tcp handshaker shutdown",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\grpc\\_channel.py:1181\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1175\u001b[0m (\n\u001b[0;32m   1176\u001b[0m     state,\n\u001b[0;32m   1177\u001b[0m     call,\n\u001b[0;32m   1178\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[0;32m   1179\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[0;32m   1180\u001b[0m )\n\u001b[1;32m-> 1181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\grpc\\_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[1;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[1;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"failed to connect to all addresses; last error: UNKNOWN: ipv4:216.58.196.170:443: tcp handshaker shutdown\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"failed to connect to all addresses; last error: UNKNOWN: ipv4:216.58.196.170:443: tcp handshaker shutdown\", grpc_status:14, created_time:\"2024-11-27T02:25:34.5253151+00:00\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mServiceUnavailable\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     result \u001b[38;5;241m=\u001b[39m target()\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mServiceUnavailable\u001b[0m: 503 failed to connect to all addresses; last error: UNKNOWN: ipv4:216.58.196.170:443: tcp handshaker shutdown",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_google_genai\\embeddings.py:227\u001b[0m, in \u001b[0;36mGoogleGenerativeAIEmbeddings.embed_documents\u001b[1;34m(self, texts, batch_size, task_type, titles, output_dimensionality)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 227\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mbatch_embed_contents(\n\u001b[0;32m    228\u001b[0m         BatchEmbedContentsRequest(requests\u001b[38;5;241m=\u001b[39mrequests, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m    229\u001b[0m     )\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:1379\u001b[0m, in \u001b[0;36mGenerativeServiceClient.batch_embed_contents\u001b[1;34m(self, request, model, requests, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m response \u001b[38;5;241m=\u001b[39m rpc(\n\u001b[0;32m   1380\u001b[0m     request,\n\u001b[0;32m   1381\u001b[0m     retry\u001b[38;5;241m=\u001b[39mretry,\n\u001b[0;32m   1382\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m   1383\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m   1384\u001b[0m )\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry_target(\n\u001b[0;32m    294\u001b[0m     target,\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicate,\n\u001b[0;32m    296\u001b[0m     sleep_generator,\n\u001b[0;32m    297\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[0;32m    298\u001b[0m     on_error\u001b[38;5;241m=\u001b[39mon_error,\n\u001b[0;32m    299\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     _retry_error_helper(\n\u001b[0;32m    154\u001b[0m         exc,\n\u001b[0;32m    155\u001b[0m         deadline,\n\u001b[0;32m    156\u001b[0m         sleep,\n\u001b[0;32m    157\u001b[0m         error_list,\n\u001b[0;32m    158\u001b[0m         predicate,\n\u001b[0;32m    159\u001b[0m         on_error,\n\u001b[0;32m    160\u001b[0m         exception_factory,\n\u001b[0;32m    161\u001b[0m         timeout,\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:221\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    216\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    217\u001b[0m         error_list,\n\u001b[0;32m    218\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mTIMEOUT,\n\u001b[0;32m    219\u001b[0m         original_timeout,\n\u001b[0;32m    220\u001b[0m     )\n\u001b[1;32m--> 221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    222\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying due to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, sleeping \u001b[39m\u001b[38;5;132;01m{:.1f}\u001b[39;00m\u001b[38;5;124ms ...\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(error_list[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], next_sleep)\n\u001b[0;32m    224\u001b[0m )\n",
      "\u001b[1;31mRetryError\u001b[0m: Timeout of 60.0s exceeded, last exception: 503 failed to connect to all addresses; last error: UNKNOWN: ipv4:216.58.196.170:443: tcp handshaker shutdown",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mGoogleGenerativeAIError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[288], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(custom_chain\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexplain git with commands using perfect examples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3022\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m   3021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3022\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3023\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3024\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3727\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3722\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m   3723\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3724\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[0;32m   3725\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   3726\u001b[0m         ]\n\u001b[1;32m-> 3727\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[0;32m   3728\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3729\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3711\u001b[0m, in \u001b[0;36mRunnableParallel.invoke.<locals>._invoke_step\u001b[1;34m(step, input, config, key)\u001b[0m\n\u001b[0;32m   3709\u001b[0m context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   3710\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m-> 3711\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   3712\u001b[0m     step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[0;32m   3713\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3714\u001b[0m     child_config,\n\u001b[0;32m   3715\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4713\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   4699\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this Runnable synchronously.\u001b[39;00m\n\u001b[0;32m   4700\u001b[0m \n\u001b[0;32m   4701\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4710\u001b[0m \u001b[38;5;124;03m    TypeError: If the Runnable is a coroutine function.\u001b[39;00m\n\u001b[0;32m   4711\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 4713\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m   4714\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke,\n\u001b[0;32m   4715\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   4716\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config(config, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc),\n\u001b[0;32m   4717\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4718\u001b[0m     )\n\u001b[0;32m   4719\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4720\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   4721\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4722\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4723\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1927\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[0;32m   1923\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1924\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m   1925\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1926\u001b[0m         Output,\n\u001b[1;32m-> 1927\u001b[0m         context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   1928\u001b[0m             call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1929\u001b[0m             func,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1930\u001b[0m             \u001b[38;5;28minput\u001b[39m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1931\u001b[0m             config,\n\u001b[0;32m   1932\u001b[0m             run_manager,\n\u001b[0;32m   1933\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1934\u001b[0m         ),\n\u001b[0;32m   1935\u001b[0m     )\n\u001b[0;32m   1936\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1937\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    395\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4567\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[1;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m   4565\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[0;32m   4566\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4567\u001b[0m     output \u001b[38;5;241m=\u001b[39m call_func_with_variable_args(\n\u001b[0;32m   4568\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, config, run_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   4569\u001b[0m     )\n\u001b[0;32m   4570\u001b[0m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[0;32m   4571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    395\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[276], line 4\u001b[0m, in \u001b[0;36mretriever\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretriever\u001b[39m(query):\n\u001b[0;32m      3\u001b[0m     retrieval \u001b[38;5;241m=\u001b[39m vector_store\u001b[38;5;241m.\u001b[39mas_retriever()\n\u001b[1;32m----> 4\u001b[0m     context \u001b[38;5;241m=\u001b[39m retrieval\u001b[38;5;241m.\u001b[39minvoke(query) \n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([i\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m context])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\retrievers.py:254\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    253\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    256\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[0;32m    257\u001b[0m         result,\n\u001b[0;32m    258\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\retrievers.py:247\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    245\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[1;32m--> 247\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\n\u001b[0;32m    248\u001b[0m         \u001b[38;5;28minput\u001b[39m, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs\n\u001b[0;32m    249\u001b[0m     )\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    251\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:1080\u001b[0m, in \u001b[0;36mVectorStoreRetriever._get_relevant_documents\u001b[1;34m(self, query, run_manager)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_relevant_documents\u001b[39m(\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m, run_manager: CallbackManagerForRetrieverRun\n\u001b[0;32m   1078\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1080\u001b[0m         docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39msimilarity_search(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_kwargs)\n\u001b[0;32m   1081\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity_score_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1082\u001b[0m         docs_and_similarities \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39msimilarity_search_with_relevance_scores(\n\u001b[0;32m   1084\u001b[0m                 query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_kwargs\n\u001b[0;32m   1085\u001b[0m             )\n\u001b[0;32m   1086\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:641\u001b[0m, in \u001b[0;36mFAISS.similarity_search\u001b[1;34m(self, query, k, filter, fetch_k, **kwargs)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search\u001b[39m(\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    623\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    628\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m    629\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \n\u001b[0;32m    631\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;124;03m        List of Documents most similar to the query.\u001b[39;00m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 641\u001b[0m     docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity_search_with_score(\n\u001b[0;32m    642\u001b[0m         query, k, \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfilter\u001b[39m, fetch_k\u001b[38;5;241m=\u001b[39mfetch_k, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    643\u001b[0m     )\n\u001b[0;32m    644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:513\u001b[0m, in \u001b[0;36mFAISS.similarity_search_with_score\u001b[1;34m(self, query, k, filter, fetch_k, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search_with_score\u001b[39m(\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    491\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    496\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tuple[Document, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[0;32m    497\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \n\u001b[0;32m    499\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m        L2 distance in float. Lower score represents more similarity.\u001b[39;00m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 513\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_query(query)\n\u001b[0;32m    514\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity_search_with_score_by_vector(\n\u001b[0;32m    515\u001b[0m         embedding,\n\u001b[0;32m    516\u001b[0m         k,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[0;32m    521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:265\u001b[0m, in \u001b[0;36mFAISS._embed_query\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_embed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_function, Embeddings):\n\u001b[1;32m--> 265\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_function\u001b[38;5;241m.\u001b[39membed_query(text)\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    267\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_function(text)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_google_genai\\embeddings.py:256\u001b[0m, in \u001b[0;36mGoogleGenerativeAIEmbeddings.embed_query\u001b[1;34m(self, text, task_type, title, output_dimensionality)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Embed a text.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;124;03m    Embedding for the text.\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    255\u001b[0m task_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_type \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETRIEVAL_QUERY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_documents(\n\u001b[0;32m    257\u001b[0m     [text],\n\u001b[0;32m    258\u001b[0m     task_type\u001b[38;5;241m=\u001b[39mtask_type,\n\u001b[0;32m    259\u001b[0m     titles\u001b[38;5;241m=\u001b[39m[title] \u001b[38;5;28;01mif\u001b[39;00m title \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    260\u001b[0m     output_dimensionality\u001b[38;5;241m=\u001b[39moutput_dimensionality,\n\u001b[0;32m    261\u001b[0m )[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_google_genai\\embeddings.py:231\u001b[0m, in \u001b[0;36mGoogleGenerativeAIEmbeddings.embed_documents\u001b[1;34m(self, texts, batch_size, task_type, titles, output_dimensionality)\u001b[0m\n\u001b[0;32m    227\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mbatch_embed_contents(\n\u001b[0;32m    228\u001b[0m             BatchEmbedContentsRequest(requests\u001b[38;5;241m=\u001b[39mrequests, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m    229\u001b[0m         )\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 231\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m GoogleGenerativeAIError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError embedding content: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    232\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;28mlist\u001b[39m(e\u001b[38;5;241m.\u001b[39mvalues) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39membeddings])\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "\u001b[1;31mGoogleGenerativeAIError\u001b[0m: Error embedding content: Timeout of 60.0s exceeded, last exception: 503 failed to connect to all addresses; last error: UNKNOWN: ipv4:216.58.196.170:443: tcp handshaker shutdown"
     ]
    }
   ],
   "source": [
    "print(custom_chain.invoke(\"explain git with commands using perfect examples\").content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68576b18-ca11-4b91-a5cf-441048b147af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
